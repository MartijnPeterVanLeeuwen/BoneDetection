# Code used in the paper

This directory contains several subdirectories that contain snippets of the code used in the paper ......... Note that these are not directly executable, but are added here to provide additional clarity on how the input for the bone detection model was generated. If you would like to reproduce our research, these folders contain the code that allows you to do so, although you must organize them yourself. 

This directory contains code to do the following things:
- [1](https://github.com/MartijnPeterVanLeeuwen/BoneDetection/blob/main/code_paper/preprocess_TotalSegmentator_scans/Combine_label_files.py): Combine the bone labels in the TotalSegmentator dataset into 1 file containing multiple bone labels.  
- [2](https://github.com/MartijnPeterVanLeeuwen/BoneDetection/blob/main/code_paper/preprocessing_yolo_input/Main_preprocessing_file.py): Preprocess the bone masks and CT scans to create an input suitable for YOLOv5 
- [3](https://github.com/MartijnPeterVanLeeuwen/BoneDetection/blob/main/code_paper/preprocess_TotalSegmentator_scans/generate_synthetic_lesion/Create_synthetic_lesions.py): Generate synthetic circular lesions in the combined bone masks. 
- [4](https://github.com/MartijnPeterVanLeeuwen/BoneDetection/blob/main/code_paper/preprocess_TotalSegmentator_scans/generate_synthetic_lesion/Fill_synthetic_lesions.py): Fill these synthetic circular lesions with Hounsfield units, often observed in osteolytic lesions 
- [5](https://github.com/MartijnPeterVanLeeuwen/BoneDetection/tree/main/code_paper/preprocess_nnUnetv2): Directory with all the code needed to prepare the training of the nnUnet model.
- 
We also provide the [training and evolve output](https://github.com/MartijnPeterVanLeeuwen/BoneDetection/tree/main/code_paper/training_yolo/training_details) generated by YOLOv5 for all three models to provide clarity on how these models were trained. Additionally, these folders also contain the hyperparameters that were used.

The same was done for the [preprocessing/planning](https://github.com/MartijnPeterVanLeeuwen/BoneDetection/tree/main/code_paper/training_nnUnet/preprocessing_plan) and the [training]([https://github.com/MartijnPeterVanLeeuwen/BoneDetection/tree/main/code_paper/training_nnUnet/preprocessing_plan](https://github.com/MartijnPeterVanLeeuwen/BoneDetection/tree/main/code_paper/training_nnUnet) of the nnUnetv2 model. Since the weights of the final model were too large to upload, these are not included in this GitHub.

To provide more details on the data that we used to train the YOLOV5 models, we also provide an [overview](https://github.com/MartijnPeterVanLeeuwen/BoneDetection/blob/main/code_paper/Datasplit_TotalSegmentator.xlsx) of the included scans, in combination with a label that shows for what dataset they were used. 

If you decide to use any of this code, please make sure to cite us (.................)
